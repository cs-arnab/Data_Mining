# -*- coding: utf-8 -*-
"""CART_Diabetes_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uZZn1i5le8QARjXdZQR50B8Ibkxd3TDI
"""

import warnings
import joblib
#import pydotplus
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, validation_curve
#from skompiler import skompile


print("- - - CART decision tree classifier - - - ")
df = pd.read_csv("/content/diabetes.csv")
df.head()

y = df["Outcome"]
X = df.drop(["Outcome"], axis=1)
# Model
cart_model = DecisionTreeClassifier(random_state=17).fit(X, y)
#y_pred for Confusion Matrix  :
y_pred = cart_model.predict(X)

#y_prob for AUC:
y_prob = cart_model.predict_proba(X)[:, 1]
# Confusion matrix
print(classification_report(y, y_pred))

# AUC
roc_auc_score(y, y_prob)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=85)
cart_model = DecisionTreeClassifier(random_state=17).fit(X_train, y_train)
# Train Error
y_pred = cart_model.predict(X_train)
y_prob = cart_model.predict_proba(X_train)[:, 1]
print(classification_report(y_train, y_pred))


roc_auc_score(y_train, y_prob)
# Test Error
y_pred = cart_model.predict(X_test)
y_prob = cart_model.predict_proba(X_test)[:, 1]
print(classification_report(y_test, y_pred))

roc_auc_score(y_test, y_prob)
cart_model = DecisionTreeClassifier(random_state=17).fit(X, y)
cv_results = cross_validate(cart_model,
                            X, y,
                            cv=10,
                            scoring=["accuracy", "f1", "roc_auc"])

cv_results['test_accuracy'].mean()
cv_results['test_f1'].mean()
cv_results['test_roc_auc'].mean()
cart_model.get_params()

# Hyperparameter set to search:
cart_params = {'max_depth': range(1, 11),
               "min_samples_split": range(2, 20)}
# GridSearchCV
cart_best_grid = GridSearchCV(cart_model,
                              cart_params,
                              cv=5,
                              n_jobs=-1,
                              verbose=True).fit(X, y)


# Best hyper parameter values:
cart_best_grid.best_params_
# Best score:
cart_best_grid.best_score_
random = X.sample(1, random_state=45)
print(random)
cart_best_grid.predict(random)
cart_final = DecisionTreeClassifier(**cart_best_grid.best_params_,
                                    random_state=17).fit(X, y)
cart_final.get_params()
# Another way to assign the best parameters to the model:
cart_final = cart_model.set_params(**cart_best_grid.best_params_).fit(X, y)
# CV error of final model:
cv_results = cross_validate(cart_final,
                            X, y,
                            cv=10,
                            scoring=["accuracy", "f1", "roc_auc"])
cv_results['test_accuracy'].mean()
cv_results['test_f1'].mean()
cv_results['test_roc_auc'].mean()
def plot_importance(model, features, num=len(X), save=False):
    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})
    plt.figure(figsize=(10, 10))
    sns.set(font_scale=1)
    sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value",
                                                                     ascending=False)[0:num])
    plt.title('Features')
    plt.tight_layout()
    plt.show()
    if save:
        plt.savefig('importances.png')
plot_importance(cart_final, X, 15)
train_score, test_score = validation_curve(
    cart_final, X=X, y=y,
    param_name='max_depth',
    param_range=range(1, 11),
    scoring="roc_auc",
    cv=10)
mean_train_score = np.mean(train_score, axis=1)
mean_test_score = np.mean(test_score, axis=1)
plt.plot(range(1, 11), mean_train_score,label="Training Score", color='b')
plt.plot(range(1, 11), mean_test_score,label="Validation Score", color='g')

plt.title("Validation Curve for CART")
plt.xlabel("Number of max_depth")
plt.ylabel("AUC")
plt.tight_layout()
plt.legend(loc='best')
plt.show()
tree_rules = export_text(cart_model, feature_names=list(X.columns))
print(tree_rules)

# ID3 decision tree classifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score


print("- - - ID3 decision tree classifier - - - ")
# Load the dataset
df = pd.read_csv("/content/diabetes.csv")

# Print column names to verify the presence of 'diabetes'
print('Column names:', df.columns)

# Split the data into training and testing sets
X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Create the ID3 decision tree classifier
clf = DecisionTreeClassifier()

# Train the classifier
clf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf.predict(X_test)

# Calculate the accuracy
accuracy = accuracy_score(y_test, y_pred)

# Print the accuracy
print('Accuracy:', accuracy)

# C4.5 decision tree classifier
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns # statistical data visualization
import sklearn
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import KFold
from sklearn.metrics import make_scorer
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.model_selection import cross_val_score
import graphviz

print("- - - C4.5 decision tree classifier - - - ")

df = pd.read_csv("/content/diabetes.csv")
df = df.dropna()

df = df[(df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']] != 0).all(axis=1)]

X = df.drop(['Outcome'], axis=1)

y = df['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)



split_data = train_test_split(df, test_size=.30)

train_data = split_data[0]
test_data = split_data[1]

outcome_train = train_data.Outcome.tolist()
outcome_test = test_data.Outcome.tolist()

train_data_remove = train_data.drop(columns = "Outcome")
test_data_remove = test_data.drop(columns = "Outcome")

X.shape, y.shape
# C4.5
features = list(df.columns)
features.remove("Outcome")

clf2 = sklearn.tree.DecisionTreeClassifier()

clf2.fit(train_data_remove, outcome_train)

dot_data = tree.export_graphviz(clf2, out_file=None, feature_names=features)
graph = graphviz.Source(dot_data)
graph.render("Diabetes_C45")

# graph
kfold=KFold(n_splits=5, shuffle=True)

y_pred = clf2.predict(X_test)

y_pred.shape

accuracy = cross_val_score(clf2,X_test, y_pred, cv=kfold, scoring='accuracy')
precision = cross_val_score(clf2,X_test, y_pred, cv=kfold, scoring='precision_weighted')
recall = cross_val_score(clf2,X_test, y_pred, cv=kfold, scoring='recall_weighted')
f1 = cross_val_score(clf2,X_test, y_pred, cv=kfold, scoring='f1_weighted')
print('accuray',  accuracy.mean())
print('precision' , precision.mean())
print('recall' ,recall.mean())
print('F1-Score' , f1.mean())

#BOXPLOT VISUALIZATION

fig1, ax1 = plt.subplots(figsize=(10,5))

red_square = dict(markerfacecolor='r', marker='s')


# grouping
all_data = [accuracy,precision,recall,f1]
ax1.set_title('performance - boxplot')

# plot box plot
ax1.boxplot(all_data,notch=False,flierprops=red_square)


#adding horizontal grid lines
ax1.yaxis.grid(True)
ax1.set_xticks([y +1 for y in range(len(all_data))])
ax1.set_xlabel('performa')
ax1.set_ylabel('score')

#add x-tick labels
plt.setp(ax1, xticks=[y+1 for y in range(len(all_data))],
         xticklabels=[ 'accuracy','precision','recall','f1_score'])
plt.show()

plt.figure(figsize=(10,7))
xx = ["cv1", "cv2", "cv3", "cv4", "cv5"] #, "cv6", "cv7", "cv8", "cv9", "cv10"
plt.plot(xx, accuracy, '--')
plt.plot(xx, precision, '--')
plt.plot(xx, recall, '--')
plt.plot(xx, f1, '--')
plt.title("comparison of each crossvalidation - SVM")
plt.xlabel("Crossvaldiation")
plt.ylabel("score")
plt.legend(["accuracy","precision", "recall", "f1-score"])
plt.grid()
plt.show()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)


cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],
                                 index=['Predict Positive:1', 'Predict Negative:0'])

sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

